{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBA Behavioral Benchmark Runner\n",
    "\n",
    "This notebook runs the behavioral benchmark suite on Google Colab's free GPU.\n",
    "\n",
    "**Setup:**\n",
    "1. Checkpoints should be in Google Drive at the configured path\n",
    "2. Results will be saved back to Drive\n",
    "3. Optionally sends notification on completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configuration { display-mode: \"form\" }\n",
    "#@markdown ### Google Drive Paths\n",
    "DRIVE_CHECKPOINT_DIR = \"/content/drive/MyDrive/DBA/checkpoints/100k\" #@param {type:\"string\"}\n",
    "DRIVE_RESULTS_DIR = \"/content/drive/MyDrive/DBA/results\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Benchmark Settings\n",
    "TESTS_PER_CATEGORY = 30 #@param {type:\"integer\"}\n",
    "SEED = 42 #@param {type:\"integer\"}\n",
    "MAX_NEW_TOKENS = 50 #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### Notification (optional)\n",
    "NOTIFY_EMAIL = \"\" #@param {type:\"string\"}\n",
    "NOTIFY_WEBHOOK = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### GitHub Repo\n",
    "GITHUB_REPO = \"theapemachine/caramba\" #@param {type:\"string\"}\n",
    "GITHUB_BRANCH = \"main\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Check GPU and Mount Drive\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"\\nDrive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Install Dependencies\n",
    "!pip install -q tiktoken pyyaml\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Clone/Update Repository\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/caramba\")\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    print(\"Updating existing repo...\")\n",
    "    !cd {REPO_DIR} && git fetch && git reset --hard origin/{GITHUB_BRANCH}\n",
    "else:\n",
    "    print(\"Cloning repo...\")\n",
    "    !git clone --depth 1 -b {GITHUB_BRANCH} https://github.com/{GITHUB_REPO}.git {REPO_DIR}\n",
    "\n",
    "print(f\"\\nRepo ready at {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Discover Checkpoints\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "checkpoint_dir = Path(DRIVE_CHECKPOINT_DIR)\n",
    "\n",
    "if not checkpoint_dir.exists():\n",
    "    raise FileNotFoundError(f\"Checkpoint directory not found: {checkpoint_dir}\")\n",
    "\n",
    "# Find all .pt files\n",
    "checkpoints = list(checkpoint_dir.rglob(\"*.pt\"))\n",
    "print(f\"Found {len(checkpoints)} checkpoint(s):\")\n",
    "for ckpt in checkpoints:\n",
    "    size_mb = ckpt.stat().st_size / 1e6\n",
    "    print(f\"  - {ckpt.name} ({size_mb:.0f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Run Benchmark\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths\n",
    "os.chdir(\"/content/caramba/research/dba\")\n",
    "sys.path.insert(0, \"/content/caramba\")\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = Path(DRIVE_RESULTS_DIR) / f\"behavioral_{timestamp}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Build checkpoint file list\n",
    "ckpt_args = \" \".join([f'\"{str(c)}\"' for c in checkpoints])\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Tests per category: {TESTS_PER_CATEGORY}\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Starting benchmark...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Run the benchmark\n",
    "!PYTHONPATH=/content/caramba python -m behavioral_suite_v2.multi_checkpoint_eval \\\n",
    "    --checkpoint-files {ckpt_args} \\\n",
    "    --output-dir \"{output_dir}\" \\\n",
    "    --tests-per-category {TESTS_PER_CATEGORY} \\\n",
    "    --seed {SEED} \\\n",
    "    --max-new-tokens {MAX_NEW_TOKENS} \\\n",
    "    --device cuda \\\n",
    "    --no-browser \\\n",
    "    --verbose\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Benchmark complete!\")\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Send Notification (Optional)\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "# Load results summary\n",
    "results_file = output_dir / \"results.json\"\n",
    "summary = \"\"\n",
    "if results_file.exists():\n",
    "    with open(results_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    summary = \"**DBA Benchmark Results**\\n\\n\"\n",
    "    for model_id in data.get('model_ids', []):\n",
    "        s = data['summaries'].get(model_id, {})\n",
    "        summary += f\"**{model_id}**\\n\"\n",
    "        summary += f\"  - Content Match: {s.get('content_match_rate', 0)*100:.1f}%\\n\"\n",
    "        summary += f\"  - Avg Score: {s.get('soft_score_avg', 0):.2f}\\n\"\n",
    "        summary += f\"  - Rep Loops: {s.get('repetition_loops', 0)}\\n\\n\"\n",
    "\n",
    "# Send webhook notification\n",
    "if NOTIFY_WEBHOOK:\n",
    "    try:\n",
    "        payload = {\n",
    "            \"text\": f\"Benchmark complete!\\n\\n{summary}\\nResults: {output_dir}\"\n",
    "        }\n",
    "        data = json.dumps(payload).encode('utf-8')\n",
    "        req = urllib.request.Request(NOTIFY_WEBHOOK, data=data, headers={'Content-Type': 'application/json'})\n",
    "        urllib.request.urlopen(req)\n",
    "        print(\"Webhook notification sent!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send webhook: {e}\")\n",
    "\n",
    "# Send email notification (using Colab's built-in)\n",
    "if NOTIFY_EMAIL:\n",
    "    try:\n",
    "        from google.colab import output\n",
    "        # This will prompt for Gmail auth if not already done\n",
    "        print(f\"Email notification would be sent to: {NOTIFY_EMAIL}\")\n",
    "        print(\"(Email sending requires additional setup with Gmail API)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Email notification not available: {e}\")\n",
    "\n",
    "print(\"\\n\" + summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7. Display Results Summary\n",
    "from IPython.display import HTML, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if dashboard was generated\n",
    "dashboard_file = output_dir / \"report.html\"\n",
    "if dashboard_file.exists():\n",
    "    print(f\"Dashboard saved to: {dashboard_file}\")\n",
    "    print(\"\\nYou can download it from Google Drive and open locally.\")\n",
    "else:\n",
    "    print(\"No dashboard file found.\")\n",
    "\n",
    "# List all output files\n",
    "print(\"\\nOutput files:\")\n",
    "for f in sorted(output_dir.iterdir()):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  - {f.name} ({size_kb:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
